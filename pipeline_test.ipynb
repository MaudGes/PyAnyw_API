{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef46eea-74e4-4311-bf8e-dac61a747189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8w/_kd6jgl573d2nsgvn5nypvym0000gp/T/ipykernel_19633/231645028.py:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom mlflow.models.signature import infer_signature\\nsignature = infer_signature(X_train, y_train)\\n\\nmlflow.sklearn.save_model(pipeline, '/home/mlflow_model', signature=signature)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "\n",
    "\"\"\"\n",
    "Pipeline used to easily define the model preprocessing steps. The pipeline is then stored using joblib. \n",
    "The model's signature is also saved to be able to reuse it later while deploying the model.\n",
    "The model itself is then stored along with other files in the 'mlflow_model' folder\n",
    "\n",
    "The selected hyperparaters for xgboost come from previous testing and results stored in mlflow (see mlruns folder)\n",
    "\"\"\"\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    test_df = pd.read_csv('credit_files/application_test.csv')\n",
    "    df = pd.read_csv('credit_files/application_train.csv')\n",
    "    print(\"Test samples: {}\".format(len(test_df)))\n",
    "    \n",
    "    # Merging\n",
    "    df = pd.concat([df,test_df])\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    #Only keeping relevant columns\n",
    "    df = df[['EXT_SOURCE_3','EXT_SOURCE_2', 'NAME_EDUCATION_TYPE_Higher education','CODE_GENDER',\n",
    "             'NAME_EDUCATION_TYPE_Secondary / secondary special','FLAG_DOCUMENT_3','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "             'REGION_RATING_CLIENT', 'EXT_SOURCE_1', 'NAME_INCOME_TYPE_Working','FLAG_EMP_PHONE','TARGET']]\n",
    "\n",
    "    #df = df.dropna(subset=['TARGET','EXT_SOURCE_3','EXT_SOURCE_2','EXT_SOURCE_1'])\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Define predictors (feature columns), while exluding payment rate\n",
    "    predictors = [col for col in df.columns if col not in ['SK_ID_CURR', 'TARGET','PAYMENT_RATE']]\n",
    "\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "#Checking the first part\n",
    "trial_1 = application_test()\n",
    "trial_1\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = trial_1.drop(columns = ['TARGET'])\n",
    "y = trial_1['TARGET']\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaling', StandardScaler()),   # StandardScaler for numerical features\n",
    "    ('model', XGBClassifier(\n",
    "        reg_lambda=2.9254886430096265,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.20333096380873394,\n",
    "        n_estimators=165,\n",
    "        colsample_bytree=0.8856368296634629,\n",
    "        reg_alpha=0.02944488920695857,\n",
    "        subsample=0.9702273343033714,\n",
    "        n_jobs=1\n",
    "    ))       # XGBoost model\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pipeline.score(X_test, y_test)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(pipeline, '/Users/maudg1/Documents/PythonA_API/pipeline_clients_traintest_2.joblib')\n",
    "\n",
    "'''\n",
    "from mlflow.models.signature import infer_signature\n",
    "signature = infer_signature(X_train, y_train)\n",
    "\n",
    "mlflow.sklearn.save_model(pipeline, '/home/mlflow_model', signature=signature)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150562b-5af4-46ce-8366-cc7091cd76fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoring",
   "language": "python",
   "name": "scoring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
